{"cells":[{"cell_type":"markdown","metadata":{"id":"RPSNvfkhWEKd"},"source":["Notebook containing initial analyses and data handling pipelines. We will grade the correctness, quality of code, and quality of textual descriptions.\n"]},{"cell_type":"markdown","source":["# Plots and Actors in Blockbusters: What Do People Favor?\n"],"metadata":{"id":"fkesNns_Yfbz"}},{"cell_type":"markdown","source":["## 1. What do those blockbusters have in their plots?\n","We want to see whether the top-selling movies are characterized by certain topics or keywords both qualitatively and quantitatively. We can also consider certain character personas in the plots."],"metadata":{"id":"dWQMHRSeZLVN"}},{"cell_type":"markdown","source":["### 1.1 Topic modeling of plots: LDA"],"metadata":{"id":"w-5YVDTiZbbE"}},{"cell_type":"code","source":["# 1.1"],"metadata":{"id":"n0jqJmxMZpCw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2 Assign each plot to a certain set of topics. \n","  (1) Get the vector representation for each topic by adding all word vectors (GloVe here maybe). \\\\\n","  (2) Build a topic vector for each plot by adding of the topic vectors, weighted by the probability of the plot belonging to this topic. "],"metadata":{"id":"SwBd3YYDZp-a"}},{"cell_type":"code","source":["# 1.2"],"metadata":{"id":"5qJsBRUOat2d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.3 Keywords extraction of each plot, by KeyBERT"],"metadata":{"id":"oTH4m0haaval"}},{"cell_type":"code","source":["# 1.3"],"metadata":{"id":"5zfn6fkUbTiQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.4 Build keyword vector for each plot by summing up all word vectors in keyword list of each plot."],"metadata":{"id":"UKb9JxQqbYij"}},{"cell_type":"code","source":["# 1.4"],"metadata":{"id":"KxDTBi4he8PB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.5 Clustering of topics and keywords.\n","This part is the backbone of this first part analysis. \n","#### 1.5.1 K-means of all plots' topic & keyword vectors.\n","#### 1.5.2 Observe clusters and visualize the revenue of each movie by color (discrete revenue level or continuous revenue color mapping)\n","#### 1.5.3 See whether certain clusters contain all top-selling or all bad-selling movies. \n","#### 1.5.4 Here ends the qualitative analysis. For quantitative analysis, compare the averaged revenues in each cluster along with uncertainty (CI maybe) to see if the effect of different clusters of topics and keywords are significant."],"metadata":{"id":"ydahSgj1fAHN"}},{"cell_type":"code","source":["# 1.5.1"],"metadata":{"id":"BufQliZ2hidj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1.5.2 & 1.5.3"],"metadata":{"id":"zUtzqVkIhjiB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.6 Split movies into different genres (groupby)\n","#### 1.6.1 Decide main genres by frequency\n","#### 1.6.2 For movies belonging to each genres, do 1.5 again to see genre-related visualization."],"metadata":{"id":"5zGWh3nDhnow"}},{"cell_type":"code","source":["# 1.6.1"],"metadata":{"id":"0lrnddVXiBSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1.6.2"],"metadata":{"id":"3H4S95vmiCe9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.7 Time-related topic & keywords changing\n","#### 1.7.1 Discretize time into decades.\n","#### 1.7.2 In each decade, do 1.5 to see time-related changing of topics and keywords."],"metadata":{"id":"n_uHT8MGiFfL"}},{"cell_type":"code","source":["# 1.7.1"],"metadata":{"id":"0s-zF-QckNqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1.7.2"],"metadata":{"id":"0lEc4_wGkOpG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# End of first part. \n","#### Problems:\n","1. Do we need to combine genres and time? May result in too many groups of data and lack of amount of data in each group."],"metadata":{"id":"LGfJ16sNkRxX"}},{"cell_type":"markdown","source":["# 2. Can this actor contribute to more revenues?"],"metadata":{"id":"6eQTXdSKkjei"}},{"cell_type":"markdown","source":["## 2.1 Actor fitness score definition and calculation\n","Definition: The difference between the movie’s revenue and the average of movies including that actor. \\\\\n","Calculation: For each actor, there is a fitness score for each movie that the actor is in. \n","Can only do this to protagonist or main characters (how to extract this)\n"],"metadata":{"id":"EQresB2ZlA51"}},{"cell_type":"markdown","source":["## 2.2 For each actor, build a regression model\n","(1) Input features: \\\\\n","  1) Movie: plot keyword vectors, topic vectors (not needed to add together, can split as features), movie genres (main genres only), movie all properties (time, area, etc) Time can be split over to a independent variable. \\\\\n","  2) Actor: all related, age, sex, etc. \\\\\n","(2) Output: the fitness score for this actor in this movie."],"metadata":{"id":"dKVVVn4AyBMg"}},{"cell_type":"markdown","source":["## 2.3 Analysis of the coeff in the model for each actor.\n","(1) Are there any actors that the regression is not significant or coefficient all close to 0? This means the actor is very general.(all movies have similar revenues)"],"metadata":{"id":"VU6eVhkJ71N9"}},{"cell_type":"markdown","source":["## 2.4 Build the model but exclude sex as input feature. \n","#### 2.4.1 Build the model for actor and actress. Are the coefficients for man significantly higher than women?\n","Potential binding effect for man and woman actors. E.g., woman has higher coeff in love movie while man "],"metadata":{"id":"y74nHaM_8bs_"}},{"cell_type":"markdown","source":["## 2.5 Genre split. Maybe"],"metadata":{"id":"p_2ZmhlS82Zr"}},{"cell_type":"markdown","source":["## 2.6 Time-related analysis. Maybe\n","Detect outdated actor?"],"metadata":{"id":"ImW766A49WBQ"}},{"cell_type":"markdown","source":["## 2.7 Actor recommendation\n","By analyzing the coefficient. Different time, different genre. "],"metadata":{"id":"-aoyomUO9Gnq"}},{"cell_type":"markdown","metadata":{"id":"KHpWqH3SWEKg"},"source":["## Play with DATA\n","\n","[CMU Movie Summary Corpus](http://www.cs.cmu.edu/~ark/personas/)\n","\n","`plot_summaries.txt` [29 M]\n","\n","Plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia.  Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary.\n","\n","\n","`corenlp_plot_summaries.tar` [628 M, separate download]\n","\n","The plot summaries from above, run through the Stanford CoreNLP pipeline (tagging, parsing, NER and coref). Each filename begins with the Wikipedia movie ID (which indexes into movie.metadata.tsv).\n","\n","\n","### TEST DATA\n","`tvtropes.clusters.txt`\n","\n","72 character types drawn from tvtropes.com, along with 501 instances of those types.  The ID field indexes into the Freebase character/actor map ID in character.metadata.tsv.\n","\n","`name.clusters.txt`\n","\n","\n","970 unique character names used in at least two different movies, along with 2,666 instances of those types.  The ID field indexes into the Freebase character/actor map ID in character.metadata.tsv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFe63t1cWEKh","executionInfo":{"status":"ok","timestamp":1667661155683,"user_tz":-60,"elapsed":364,"user":{"displayName":"Yitao Xu","userId":"08412486466278411597"}},"outputId":"c7d98705-047c-4092-d9a6-c5b8f84ddb7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/EPFL_course_project/ada-2022-project-superplainteamname2022\n","./data/setup.sh: 19: ./data/setup.sh: Syntax error: \"fi\" unexpected (expecting \"then\")\n"]}],"source":["# If you already downloaded CoreNLP data, you can avoid downloading by\n","# put it to data/corenlp_plot_summaries.tar\n","%cd /content/drive/MyDrive/EPFL_course_project/ada-2022-project-superplainteamname2022/\n","!sh ./data/setup.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xt8R_Fe_WEKj"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtNNn5ZSWEKj","outputId":"710445c7-02f6-40c7-dac4-e6576d86142b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movie_id</th>\n","      <th>freebase_movie_id</th>\n","      <th>movie_name</th>\n","      <th>movie_release_date</th>\n","      <th>movie_box_office_revenue</th>\n","      <th>movie_runtime</th>\n","      <th>movie_languages</th>\n","      <th>movie_countries</th>\n","      <th>movie_genres</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>975900</td>\n","      <td>/m/03vyhn</td>\n","      <td>Ghosts of Mars</td>\n","      <td>2001-08-24</td>\n","      <td>14010832.0</td>\n","      <td>98.0</td>\n","      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n","      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n","      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3196793</td>\n","      <td>/m/08yl5d</td>\n","      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n","      <td>2000-02-16</td>\n","      <td>NaN</td>\n","      <td>95.0</td>\n","      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n","      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n","      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28463795</td>\n","      <td>/m/0crgdbh</td>\n","      <td>Brun bitter</td>\n","      <td>1988-01-01</td>\n","      <td>NaN</td>\n","      <td>83.0</td>\n","      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n","      <td>{\"/m/05b4w\": \"Norway\"}</td>\n","      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9363483</td>\n","      <td>/m/0285_cd</td>\n","      <td>White Of The Eye</td>\n","      <td>1987-01-01</td>\n","      <td>NaN</td>\n","      <td>110.0</td>\n","      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n","      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n","      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>261236</td>\n","      <td>/m/01mrr1</td>\n","      <td>A Woman in Flames</td>\n","      <td>1983-01-01</td>\n","      <td>NaN</td>\n","      <td>106.0</td>\n","      <td>{\"/m/04306rv\": \"German Language\"}</td>\n","      <td>{\"/m/0345h\": \"Germany\"}</td>\n","      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   movie_id freebase_movie_id  \\\n","0    975900         /m/03vyhn   \n","1   3196793         /m/08yl5d   \n","2  28463795        /m/0crgdbh   \n","3   9363483        /m/0285_cd   \n","4    261236         /m/01mrr1   \n","\n","                                          movie_name movie_release_date  \\\n","0                                     Ghosts of Mars         2001-08-24   \n","1  Getting Away with Murder: The JonBenét Ramsey ...         2000-02-16   \n","2                                        Brun bitter         1988-01-01   \n","3                                   White Of The Eye         1987-01-01   \n","4                                  A Woman in Flames         1983-01-01   \n","\n","   movie_box_office_revenue  movie_runtime  \\\n","0                14010832.0           98.0   \n","1                       NaN           95.0   \n","2                       NaN           83.0   \n","3                       NaN          110.0   \n","4                       NaN          106.0   \n","\n","                      movie_languages  \\\n","0  {\"/m/02h40lc\": \"English Language\"}   \n","1  {\"/m/02h40lc\": \"English Language\"}   \n","2  {\"/m/05f_3\": \"Norwegian Language\"}   \n","3  {\"/m/02h40lc\": \"English Language\"}   \n","4   {\"/m/04306rv\": \"German Language\"}   \n","\n","                             movie_countries  \\\n","0  {\"/m/09c7w0\": \"United States of America\"}   \n","1  {\"/m/09c7w0\": \"United States of America\"}   \n","2                     {\"/m/05b4w\": \"Norway\"}   \n","3             {\"/m/07ssc\": \"United Kingdom\"}   \n","4                    {\"/m/0345h\": \"Germany\"}   \n","\n","                                        movie_genres  \n","0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n","1  {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n","2  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n","3  {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n","4                            {\"/m/07s9rl0\": \"Drama\"}  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# `movie.metadata.tsv` [3.4 M]\n","\n","# Metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n","\n","# 1. Wikipedia movie ID\n","# 2. Freebase movie ID\n","# 3. Movie name\n","# 4. Movie release date\n","# 5. Movie box office revenue\n","# 6. Movie runtime\n","# 7. Movie languages (Freebase ID:name tuples)\n","# 8. Movie countries (Freebase ID:name tuples)\n","# 9. Movie genres (Freebase ID:name tuples)\n","\n","movie_metadata = pd.read_csv(\n","    \"./data/MovieSummaries/movie.metadata.tsv\",\n","    sep=\"\\t\",\n","    header=None,\n","    names=[\n","        \"movie_id\",\n","        \"freebase_movie_id\",\n","        \"movie_name\",\n","        \"movie_release_date\",\n","        \"movie_box_office_revenue\",\n","        \"movie_runtime\",\n","        \"movie_languages\",\n","        \"movie_countries\",\n","        \"movie_genres\",\n","    ],\n","    parse_dates=[\"movie_release_date\"],\n","    date_parser=lambda x: pd.to_datetime(x, errors=\"coerce\"),\n",")\n","\n","movie_metadata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJ36Us2pWEKk"},"outputs":[],"source":["# movie id is wikipedia page id\n","# https://en.wikipedia.org/?curid={movie_id}\n","\n","# How to use query freebase id?\n","# https://edstem.org/eu/courses/134/discussion/3845\n","\n","# https://query.wikidata.org/#PREFIX%20wd%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fdirect%2F%3E%0APREFIX%20wikibase%3A%20%3Chttp%3A%2F%2Fwikiba.se%2Fontology%23%3E%0A%0ASELECT%20%20%3Fs%20%3FsLabel%20%3Fp%20%20%3Fo%20%3FoLabel%20WHERE%20%7B%0A%20%3Fs%20wdt%3AP646%20%22%2Fm%2F0181lj%22%20%0A%0A%20%20%20SERVICE%20wikibase%3Alabel%20%7B%0A%20%20%20%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20.%0A%20%20%20%7D%0A%20%7D"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UrBr152oWEKk"},"outputs":[],"source":["# `character.metadata.tsv` [14 M]\n","\n","# Metadata for 450,669 characters aligned to the movies above, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n","\n","# 1. Wikipedia movie ID\n","# 2. Freebase movie ID\n","# 3. Movie release date\n","# 4. Character name\n","# 5. Actor date of birth\n","# 6. Actor gender\n","# 7. Actor height (in meters)\n","# 8. Actor ethnicity (Freebase ID)\n","# 9. Actor name\n","# 10. Actor age at movie release\n","# 11. Freebase character/actor map ID\n","# 12. Freebase character ID\n","# 13. Freebase actor ID\n","\n","character_metadata = pd.read_csv(\n","    \"./data/MovieSummaries/character.metadata.tsv\",\n","    sep=\"\\t\",\n","    header=None,\n","    names=[\n","        \"movie_id\",\n","        \"freebase_movie_id\",\n","        \"movie_release_date\",\n","        \"character_name\",\n","        \"actor_birthdate\",\n","        \"actor_gender\",\n","        \"actor_height\",\n","        \"actor_ethnicity\",\n","        \"actor_name\",\n","        \"actor_age\",\n","        \"freebase_character_actor_map_id\",\n","        \"freebase_character_id\",\n","        \"freebase_actor_id\",\n","    ],\n","    parse_dates=[\"movie_release_date\", \"actor_birthdate\"],\n","    date_parser=lambda x: pd.to_datetime(x, errors=\"coerce\", utc=True),\n",")\n","character_metadata['movie_release_date']= character_metadata['movie_release_date'].dt.date\n","character_metadata['actor_birthdate']= character_metadata['actor_birthdate'].dt.date\n","character_metadata.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Dy2gM2yWEKl","outputId":"f8f5486f-8e14-49b8-f4e5-4d468f7ab269"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>movie_release_date</th>\n","      <th>actor_birthdate</th>\n","      <th>actor_age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>767</th>\n","      <td>1934-05-02</td>\n","      <td>1963-11-07</td>\n","      <td>-29.0</td>\n","    </tr>\n","    <tr>\n","      <th>2286</th>\n","      <td>1918-04-14</td>\n","      <td>1931-03-25</td>\n","      <td>-12.0</td>\n","    </tr>\n","    <tr>\n","      <th>3892</th>\n","      <td>1965-01-01</td>\n","      <td>1983-03-03</td>\n","      <td>-18.0</td>\n","    </tr>\n","    <tr>\n","      <th>6666</th>\n","      <td>1924-01-01</td>\n","      <td>1972-11-07</td>\n","      <td>-48.0</td>\n","    </tr>\n","    <tr>\n","      <th>7188</th>\n","      <td>1955-08-07</td>\n","      <td>1973-08-01</td>\n","      <td>-17.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>446570</th>\n","      <td>1999-10-03</td>\n","      <td>NaT</td>\n","      <td>-937.0</td>\n","    </tr>\n","    <tr>\n","      <th>446581</th>\n","      <td>1955-01-01</td>\n","      <td>1967-05-31</td>\n","      <td>-12.0</td>\n","    </tr>\n","    <tr>\n","      <th>446583</th>\n","      <td>1944-02-23</td>\n","      <td>1947-05-28</td>\n","      <td>-3.0</td>\n","    </tr>\n","    <tr>\n","      <th>446816</th>\n","      <td>1941-06-20</td>\n","      <td>1957-04-19</td>\n","      <td>-15.0</td>\n","    </tr>\n","    <tr>\n","      <th>447210</th>\n","      <td>1932-08-09</td>\n","      <td>1942-02-08</td>\n","      <td>-9.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>433 rows × 3 columns</p>\n","</div>"],"text/plain":["       movie_release_date actor_birthdate  actor_age\n","767            1934-05-02      1963-11-07      -29.0\n","2286           1918-04-14      1931-03-25      -12.0\n","3892           1965-01-01      1983-03-03      -18.0\n","6666           1924-01-01      1972-11-07      -48.0\n","7188           1955-08-07      1973-08-01      -17.0\n","...                   ...             ...        ...\n","446570         1999-10-03             NaT     -937.0\n","446581         1955-01-01      1967-05-31      -12.0\n","446583         1944-02-23      1947-05-28       -3.0\n","446816         1941-06-20      1957-04-19      -15.0\n","447210         1932-08-09      1942-02-08       -9.0\n","\n","[433 rows x 3 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["character_metadata.query('actor_age <= 0')[['movie_release_date', 'actor_birthdate','actor_age']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3wD3DFXWEKm","outputId":"0d8d61b5-ce0b-4780-c4e0-ba26421c6398"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/ck/2ms8pxqd15xc91xlcv_lcbrh0000gn/T/ipykernel_54328/68666177.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  ages['calculated_age'] = calculated_age\n","/var/folders/ck/2ms8pxqd15xc91xlcv_lcbrh0000gn/T/ipykernel_54328/68666177.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  ages['diff'] = ages['actor_age'] - ages['calculated_age']\n"]},{"name":"stdout","output_type":"stream","text":["diff>1 :Empty DataFrame\n","Columns: [freebase_actor_id, actor_age, actor_birthdate, movie_release_date, calculated_age, diff]\n","Index: []\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>freebase_actor_id</th>\n","      <th>actor_age</th>\n","      <th>actor_birthdate</th>\n","      <th>movie_release_date</th>\n","      <th>calculated_age</th>\n","      <th>diff</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>34</th>\n","      <td>/m/0bwh7d8</td>\n","      <td>40.0</td>\n","      <td>1947-01-01</td>\n","      <td>1988-01-01</td>\n","      <td>41.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>164</th>\n","      <td>/m/02w09gx</td>\n","      <td>36.0</td>\n","      <td>1949-01-01</td>\n","      <td>1986-01-01</td>\n","      <td>37.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>/m/01wlly9</td>\n","      <td>-29.0</td>\n","      <td>1963-11-07</td>\n","      <td>1934-05-02</td>\n","      <td>-30.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>/m/07m9cm</td>\n","      <td>44.0</td>\n","      <td>1963-12-19</td>\n","      <td>2008-12-18</td>\n","      <td>45.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1179</th>\n","      <td>/m/09vz5s</td>\n","      <td>36.0</td>\n","      <td>1937-01-01</td>\n","      <td>1974-01-01</td>\n","      <td>37.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>447210</th>\n","      <td>/m/02pb53</td>\n","      <td>-9.0</td>\n","      <td>1942-02-08</td>\n","      <td>1932-08-09</td>\n","      <td>-10.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>447504</th>\n","      <td>/m/0f12r29</td>\n","      <td>76.0</td>\n","      <td>1933-01-01</td>\n","      <td>2010-01-01</td>\n","      <td>77.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>449604</th>\n","      <td>/m/0cm19f</td>\n","      <td>56.0</td>\n","      <td>1915-01-01</td>\n","      <td>1972-01-01</td>\n","      <td>57.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>449664</th>\n","      <td>/m/01g42</td>\n","      <td>52.0</td>\n","      <td>1913-11-02</td>\n","      <td>1966-11-02</td>\n","      <td>53.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>450330</th>\n","      <td>/m/08wfyr</td>\n","      <td>68.0</td>\n","      <td>1934-01-01</td>\n","      <td>2003-01-01</td>\n","      <td>69.0</td>\n","      <td>-1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1110 rows × 6 columns</p>\n","</div>"],"text/plain":["       freebase_actor_id  actor_age actor_birthdate movie_release_date  \\\n","34            /m/0bwh7d8       40.0      1947-01-01         1988-01-01   \n","164           /m/02w09gx       36.0      1949-01-01         1986-01-01   \n","767           /m/01wlly9      -29.0      1963-11-07         1934-05-02   \n","962            /m/07m9cm       44.0      1963-12-19         2008-12-18   \n","1179           /m/09vz5s       36.0      1937-01-01         1974-01-01   \n","...                  ...        ...             ...                ...   \n","447210         /m/02pb53       -9.0      1942-02-08         1932-08-09   \n","447504        /m/0f12r29       76.0      1933-01-01         2010-01-01   \n","449604         /m/0cm19f       56.0      1915-01-01         1972-01-01   \n","449664          /m/01g42       52.0      1913-11-02         1966-11-02   \n","450330         /m/08wfyr       68.0      1934-01-01         2003-01-01   \n","\n","        calculated_age  diff  \n","34                41.0  -1.0  \n","164               37.0  -1.0  \n","767              -30.0   1.0  \n","962               45.0  -1.0  \n","1179              37.0  -1.0  \n","...                ...   ...  \n","447210           -10.0   1.0  \n","447504            77.0  -1.0  \n","449604            57.0  -1.0  \n","449664            53.0  -1.0  \n","450330            69.0  -1.0  \n","\n","[1110 rows x 6 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# play with the data - check the calculation of actor age\n","\n","calculated_age = (character_metadata.movie_release_date - character_metadata.actor_birthdate).astype('timedelta64[Y]')\n","ages = character_metadata[['freebase_actor_id', 'actor_age', 'actor_birthdate', 'movie_release_date']]\n","ages['calculated_age'] = calculated_age\n","ages['diff'] = ages['actor_age'] - ages['calculated_age']\n","\n","print(\"diff>1 :{}\".format(ages[ages['diff'].apply(lambda x: not np.isnan(x) and np.abs(x) > 1)]))\n","ages[ages['diff'].apply(lambda x: not np.isnan(x) and x != 0)]"]},{"cell_type":"markdown","metadata":{"id":"nOKRLNWWWEKm"},"source":["Some ages has error 1. Some ages are negative..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpZyJ161WEKm"},"outputs":[],"source":["# CoreNLP: https://stanfordnlp.github.io/CoreNLP/\n","\n","def load_coreNLP_data(wiki_movie_id: int):\n","    \"\"\"\n","    data/corenlp_plot_summaries/{wiki_movie_id}.xml.gz\n","    \"\"\"\n","    from bs4 import BeautifulSoup\n","    import gzip\n","    \n","    xml = f'data/corenlp_plot_summaries/{wiki_movie_id}.xml.gz'\n","    with gzip.open(xml, 'rb') as f:\n","        soup = BeautifulSoup(f, 'xml')\n","    return soup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dCvQ0MMyWEKn","outputId":"072cf4fb-d4cc-4b2b-9c0f-8c16b85dbded"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'coreference', 'sentences'}\n","{'sentence'}\n","{'parse', 'basic-dependencies', 'collapsed-dependencies', 'collapsed-ccprocessed-dependencies', 'tokens'}\n","{'coreference'}\n","{'mention'}\n","<coreference>\n"," <mention representative=\"true\">\n","  <sentence>\n","   1\n","  </sentence>\n","  <start>\n","   23\n","  </start>\n","  <end>\n","   26\n","  </end>\n","  <head>\n","   24\n","  </head>\n"," </mention>\n"," <mention>\n","  <sentence>\n","   3\n","  </sentence>\n","  <start>\n","   18\n","  </start>\n","  <end>\n","   20\n","  </end>\n","  <head>\n","   18\n","  </head>\n"," </mention>\n","</coreference>\n","\n"]}],"source":["data = load_coreNLP_data(3217)\n","# data is like:\n","# <document>\n","#   <sentences>\n","#       <sentence>\n","#           ...\n","#       </sentence>\n","#   </sentences>\n","#   <coreference>\n","#      <coreference>\n","#         ...\n","#      </coreference>\n","#  </coreference>\n","# </document>\n","print(set(tag.name for tag in data.document.find_all(recursive=False)))\n","print(set(tag.name for tag in data.sentences.find_all(recursive=False)))\n","print(set(tag.name for tag in data.sentences.sentence.find_all(recursive=False)))\n","# print(data.sentence)\n","\n","print(set(tag.name for tag in data.coreference.find_all(recursive=False)))\n","print(set(tag.name for tag in data.coreference.coreference.find_all(recursive=False)))\n","print(data.coreference.coreference.prettify())\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('data-analysis')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"90ebcbcaf500e85070f369e8fffbd2e1a65d40f93cb30efbd2d5d28433180a4e"}},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}